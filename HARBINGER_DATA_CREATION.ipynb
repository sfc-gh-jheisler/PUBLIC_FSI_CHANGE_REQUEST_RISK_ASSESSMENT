{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "py_generate_data_prompt",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "def generate_data_prompt(): \n",
    "    prompt= f\"\"\"\n",
    "    <role>\n",
    "    You are an experienced dev ops professional deeply knowledgeable on computer systems that support a very large company. You are an expert at the metadata that is captured about change requests.\n",
    "    A change request is a formal proposal for an alteration to the computer system that you manage.\n",
    "    As a dev ops expert, you specialize in creating the detailed information that is captured about a change request.\n",
    "    </role>\n",
    "\n",
    "    <task>: Follow these instructions,\n",
    "    1) Considering the data_specs and your <role> create data definition language (ddl) to create a table with the appropriate columns. Then, \n",
    "    2) Considering the data_specs section and your <role> create data definition language (ddl) to fill the table with synthetic data set about change requests. \n",
    "    </task>\n",
    "    \n",
    "    <data_specs> \n",
    "    The metadata for the data is below and follows this format: (column_name: data_type : description : sample_values):\n",
    "    \n",
    "    Description: VARCHAR(16777216) : A summary of the change : 'This change request proposes an upgrade to the existing DataSync API from version 3.2 to 3.4 in the Production environment. The update includes several key performance optimizations, enhanced security features, and bug fixes that address issues with data consistency and processing time.\n",
    "    The major components of this change include:\n",
    "    \n",
    "    API Version Update: Migrating from DataSync API v3.2 to v3.4 to support faster data ingestion and processing.\n",
    "    Security Enhancements: Implementation of OAuth 2.0-based authentication to replace the legacy basic authentication mechanism, improving overall security for API transactions.\n",
    "    Error Handling: Enhanced error codes and more descriptive responses for improved debugging in the event of failure.\n",
    "    Database Schema Update: Modifications to the backend MySQL database to accommodate new data types introduced in version 3.4.\n",
    "    Testing will be performed in the staging environment (v3.4-Stage) before deployment to ensure backwards compatibility with existing systems. No downtime is expected during the deployment, but a rollback plan has been prepared in case of critical issues.', \n",
    "    'This change request outlines modifications to the current load balancer configuration in the production environment. The goal is to optimize traffic distribution across the primary application servers (AppSrv-01, AppSrv-02, AppSrv-03) to improve system reliability during high traffic spikes.\n",
    "\n",
    "    Current Setup: The load balancer (LB-Prod) is currently set to a round-robin algorithm with a static weight of 1 for each server.\n",
    "    Proposed Change: Implement a dynamic load balancing algorithm using least connections for improved resource distribution based on real-time traffic.\n",
    "    Configuration Details:\n",
    "    Modify the load balancing strategy from round-robin to Least Connections for AppSrv-01, AppSrv-02, and AppSrv-03.\n",
    "    Increase the weight of AppSrv-03 (currently at weight 1) to weight 2, as it is the most powerful server.\n",
    "    Implement automatic failover configuration in the event of server downtime to reduce service interruptions.\n",
    "    Adjust session persistence settings for clients with long transactions to be sticky to the same backend server.\n",
    "    Testing will be conducted on a staging environment (LB-Staging) to ensure optimal performance before full deployment. Expected downtime is minimal and will occur during the initial configuration phase.', \n",
    "    \n",
    "    'This change request aims to reconfigure the existing MySQL database cluster (DBCluster-Prod) to support horizontal scaling by introducing a sharded database model. This will help improve read and write throughput, especially for the rapidly growing user base in the e-commerce application.\n",
    "    \n",
    "    Current Setup: The current setup consists of a single master node (DBMaster-Prod) and two read replicas (DBReplica1, DBReplica2).\n",
    "    Proposed Change:\n",
    "    Introduce horizontal sharding by partitioning the user data across four separate database instances: DBShard-01, DBShard-02, DBShard-03, DBShard-04.\n",
    "    Implement MySQL ProxySQL to handle routing of read and write queries to the appropriate shard based on the user’s region.\n",
    "    Set up automatic sharding management to allow for easy redistribution of data as new shards are added in the future.\n",
    "    Deploy a Data Sync Tool for initial data migration from DBMaster-Prod to the new shards.\n",
    "    Update application logic to support sharded database queries, ensuring that application components such as user authentication and order management are correctly routed to the right database shards.\n",
    "    Testing will be conducted in a dedicated staging environment (DBCluster-Staging) to verify data integrity and application performance. A backup of all critical data will be taken before the migration begins. Expected downtime is approximately 30 minutes for initial shard setup.'\n",
    "        \n",
    "    Date: DATE : The date the request was made : 2024-11-11\n",
    "    \n",
    "    Impact: VARCHAR(4000) : How the change will affect the project, including cost, quality, risk, scope, duration, and schedule \n",
    "    \n",
    "    Priority: VARCHAR(400) : How quickly the change should be approved and implemented : 'immediately', 'within release window', 'after approval'\n",
    "    \n",
    "    Risk: VARCHAR(400) : The risk level of the change as described by development team : 'low risk', 'moderate risk', 'high risk'\n",
    "    \n",
    "    Justification: VARCHAR(4000) : The reason for the change : 'preventative maintenance', 'patch', 'planned release as part of project koala'\n",
    "    \n",
    "    State: VARCHAR(400) : The status of the change request : 'new', 'under review', 'approved', 'deferred', 'rejected' \n",
    "    \n",
    "    Disposition: VARCHAR(400) : An explanation for approved, deferred, or rejected changes : 'no peer review', 'manager override', 'uniform agreement'\n",
    "    \n",
    "    Category: VARCHAR(400) : The category of the change : 'planned', 'unplanned', 'emergency' \n",
    "    \n",
    "    Change number: VARCHAR(100) : A unique ID for tracking the request :'AB1672', '723CS', '6D62EE'\n",
    "    \n",
    "    </data_specs>\n",
    "\n",
    "    <output>\n",
    "    Produce 150 rows of data with this data. Absolutely only return the sql and no other wording.\n",
    "    </output>\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "py_build_logic",
    "resultHeight": 565
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from snowflake.cortex import Complete\n",
    "from snowflake.snowpark.functions import col, call_udf\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "#get a session\n",
    "session = get_active_session()\n",
    "\n",
    "#each row's columns are collapsed into a json object. that is easier to pass to the model\n",
    "#NOTICE: I am calling my generate_prompt function and passing my row as json.\n",
    "#NOTICE that I am calling complete function here (https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex)\n",
    "    # VALUE CALLOUT: I could switch out any LLM I have access to (https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability)\n",
    "\n",
    "df = Complete('reka-core', generate_data_prompt())\n",
    "\n",
    "#!!look into call_udf amd call function for further efficiency gain via parallelisation!!\n",
    "    # call_udf: https://docs.snowflake.com/en/developer-guide/snowpark/python/calling-functions#calling-user-defined-functions-udfs\n",
    "    # call_function: https://docs.snowflake.com/en/developer-guide/snowpark/python/calling-functions#calling-system-defined-functions\n",
    "\n",
    "#show us the data\n",
    "st.write(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5068edd-ecbf-483d-a651-cc84ae620bc0",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_table",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE ChangeRequests (\n",
    "       ChangeNumber VARCHAR(100),\n",
    "       Description VARCHAR(16777216),\n",
    "       Date DATE,\n",
    "       Impact VARCHAR(4000),\n",
    "       Priority VARCHAR(400),\n",
    "       Risk VARCHAR(400),\n",
    "       Justification VARCHAR(4000),\n",
    "       State VARCHAR(400),\n",
    "       Disposition VARCHAR(400),\n",
    "       Category VARCHAR(400)\n",
    "   );\n",
    "\n",
    "   INSERT INTO ChangeRequests (ChangeNumber, Description, Date, Impact, Priority, Risk, Justification, State, Disposition, Category) VALUES\n",
    "   ('AB1672', 'This change request proposes an upgrade to the existing DataSync API from version 3.2 to 3.4 in the Production environment. The update includes several key performance optimizations, enhanced security features, and bug fixes that address issues with data consistency and processing time. The major components of this change include: API Version Update: Migrating from DataSync API v3.2 to v3.4 to support faster data ingestion and processing. Security Enhancements: Implementation of OAuth 2.0-based authentication to replace the legacy basic authentication mechanism, improving overall security for API transactions. Error Handling: Enhanced error codes and more descriptive responses for improved debugging in the event of failure. Database Schema Update: Modifications to the backend MySQL database to accommodate new data types introduced in version 3.4. Testing will be performed in the staging environment (v3.4-Stage) before deployment to ensure backwards compatibility with existing systems. No downtime is expected during the deployment, but a rollback plan has been prepared in case of critical issues.', '2024-11-11', 'Improved performance and security with minimal downtime', 'immediately', 'low risk', 'preventative maintenance', 'new', 'no peer review', 'planned'),\n",
    "   ('723CS', 'This change request outlines modifications to the current load balancer configuration in the production environment. The goal is to optimize traffic distribution across the primary application servers (AppSrv-01, AppSrv-02, AppSrv-03) to improve system reliability during high traffic spikes. Current Setup: The load balancer (LB-Prod) is currently set to a round-robin algorithm with a static weight of 1 for each server. Proposed Change: Implement a dynamic load balancing algorithm using least connections for improved resource distribution based on real-time traffic. Configuration Details: Modify the load balancing strategy from round-robin to Least Connections for AppSrv-01, AppSrv-02, and AppSrv-03. Increase the weight of AppSrv-03 (currently at weight 1) to weight 2, as it is the most powerful server. Implement automatic failover configuration in the event of server downtime to reduce service interruptions. Adjust session persistence settings for clients with long transactions to be sticky to the same backend server. Testing will be conducted on a staging environment (LB-Staging) to ensure optimal performance before full deployment. Expected downtime is minimal and will occur during the initial configuration phase.', '2024-11-11', 'Improved system reliability with minimal downtime', 'within release window', 'moderate risk', 'patch', 'under review', 'manager override', 'unplanned'),\n",
    "   ('6D62EE', 'This change request aims to reconfigure the existing MySQL database cluster (DBCluster-Prod) to support horizontal scaling by introducing a sharded database model. This will help improve read and write throughput, especially for the rapidly growing user base in the e-commerce application. Current Setup: The current setup consists of a single master node (DBMaster-Prod) and two read replicas (DBReplica1, DBReplica2). Proposed Change: Introduce horizontal sharding by partitioning the user data across four separate database instances: DBShard-01, DBShard-02, DBShard-03, DBShard-04. Implement MySQL ProxySQL to handle routing of read and write queries to the appropriate shard based on the user’s region. Set up automatic sharding management to allow for easy redistribution of data as new shards are added in the future. Deploy a Data Sync Tool for initial data migration from DBMaster-Prod to the new shards. Update application logic to support sharded database queries, ensuring that application components such as user authentication and order management are correctly routed to the right database shards. Testing will be conducted in a dedicated staging environment (DBCluster-Staging) to verify data integrity and application performance. A backup of all critical data will be taken before the migration begins. Expected downtime is approximately 30 minutes for initial shard setup.', '2024-11-11', 'Improved read and write throughput with minimal downtime', 'after approval', 'high risk', 'planned release as part of project koala', 'approved', 'uniform agreement', 'emergency'),\n",
    " ('AB1673', 'This change request proposes a server migration from the legacy physical servers (Srv-Old-01, Srv-Old-02) to a new virtualized environment in VMware vSphere. The migration will improve resource allocation, reduce hardware costs, and provide better scalability. The new setup will include 4 VMs (VM-01 to VM-04) configured for redundancy and load balancing. Initial migration testing will be done on the staging environment (VMware-Staging), with a 2-hour maintenance window required for the final migration.', '2024-11-11', 'Improved scalability and cost savings', 'within maintenance window', 'moderate risk', 'cost optimization', 'approved', 'no peer review', 'planned'),\n",
    "   ('AB1674', 'This change request outlines the integration of the new Customer Relationship Management (CRM) tool into the existing infrastructure. The CRM tool, Salesforce Cloud, will replace the legacy in-house system. The integration will involve data migration, API connections to internal systems, and user training. The migration process will begin in the staging environment, followed by a phased rollout to the production environment.', '2024-11-11', 'Enhanced customer interaction and reporting capabilities', 'within release window', 'low risk', 'system replacement', 'new', 'peer-reviewed', 'planned'),\n",
    "   ('AB1675', 'This change request involves patching the security vulnerabilities in the web application firewall (WAF) configuration. The update will address critical vulnerabilities identified in the recent security audit. Changes will include tightening rules for SQL injection and cross-site scripting (XSS), and enhancing logging for monitoring suspicious activity. Testing will be done in the staging environment before pushing the update live in production.', '2024-11-11', 'Enhanced security of web applications', 'immediately', 'high risk', 'security patch', 'under review', 'manager override', 'unplanned'),\n",
    "   ('AB1676', 'This change request proposes the upgrade of the Apache web server from version 2.4.46 to 2.4.54. The upgrade includes performance improvements, security patches, and support for HTTP/3. Additionally, several deprecated modules will be removed, and new SSL/TLS certificates will be installed. No downtime is expected, but a rollback plan is in place for potential issues.', '2024-11-11', 'Improved performance and security', 'within release window', 'low risk', 'system upgrade', 'new', 'no peer review', 'planned'),\n",
    "   ('AB1677', 'This change request involves expanding the cloud storage capacity on AWS S3 by 5 TB to accommodate growing user data from the mobile app. The expansion will be managed using an automated script to ensure consistent provisioning, and backups will be taken before initiating the process. The expansion is expected to be seamless with minimal user impact.', '2024-11-11', 'Increased storage capacity with no downtime', 'within maintenance window', 'low risk', 'storage expansion', 'approved', 'peer-reviewed', 'unplanned'),\n",
    "   ('AB1678', 'This change request suggests a reconfiguration of the DNS settings for the company’s public-facing websites. The objective is to improve redundancy and performance by integrating Route 53 with health checks and failover routing. The change will be tested in a sandbox environment before being pushed live to avoid downtime during the migration.', '2024-11-11', 'Improved availability and performance', 'within release window', 'moderate risk', 'performance optimization', 'under review', 'no peer review', 'planned'),\n",
    "   ('AB1679', 'This change request proposes a new backup solution using Veeam Backup & Replication. The current backup system is inefficient and requires manual intervention. The new solution will automate backup jobs, include replication to an offsite location, and implement encryption for secure data storage. The initial setup and testing will occur in the staging environment before going live.', '2024-11-11', 'Automated backups with enhanced security', 'within maintenance window', 'low risk', 'new system installation', 'approved', 'manager override', 'planned'),\n",
    "   ('AB1680', 'This change request involves the migration of the internal email system from Exchange Server 2016 to Microsoft 365. This migration will enable enhanced collaboration features, improve user experience, and reduce on-premises maintenance. The migration will be carried out in stages, starting with a pilot group, and full deployment will occur over the course of 2 weeks. A fallback plan is in place in case of service disruption.', '2024-11-11', 'Improved email functionality and collaboration tools', 'after approval', 'moderate risk', 'service migration', 'new', 'peer-reviewed', 'unplanned'),\n",
    "   ('AB1681', 'This change request aims to upgrade the enterprise network infrastructure by replacing the aging core switches with Cisco Catalyst 9300 models. The upgrade will enhance network speed, support higher throughput, and improve security features such as 802.1X authentication. The work will be scheduled for a weekend to minimize downtime and will involve several phases of testing.', '2024-11-11', 'Improved network performance and security', 'within release window', 'high risk', 'infrastructure upgrade', 'approved', 'uniform agreement', 'planned'),\n",
    "   ('AB1682', 'This change request proposes to integrate the payment gateway API (Stripe) into the company’s e-commerce platform to replace the legacy payment processor. The integration will include testing for PCI DSS compliance, customer notification, and system load testing to ensure performance during peak traffic periods. The rollout will happen incrementally, with extensive monitoring during the first week.', '2024-11-11', 'Enhanced payment processing capabilities', 'immediately', 'moderate risk', 'service upgrade', 'new', 'no peer review', 'unplanned'),\n",
    "('AB1673', 'This change request proposes the migration of internal file storage from an on-premises SAN (Storage Area Network) to Amazon S3 for better scalability and cost optimization. The process will involve the migration of over 10 TB of data using AWS DataSync, with a staged migration plan that includes data validation, checksum comparisons, and testing to ensure integrity. The new solution will leverage S3 lifecycle policies for automated archival and deletion, and a CloudFront CDN will be configured for faster content delivery. The migration will happen in batches, with a 48-hour downtime window per batch, during which all file-related services will be unavailable.', '2024-11-11', 'Enhanced scalability and reduced operational cost', 'within release window', 'moderate risk', 'storage migration', 'approved', 'manager override', 'unplanned'),\n",
    "   ('AB1674', 'This change request involves the reconfiguration of the Kubernetes cluster running in Google Kubernetes Engine (GKE). The changes will include increasing the number of nodes in the cluster from 5 to 15 to meet the increasing load of microservices. The configuration will also include moving to a multi-zone setup to enhance fault tolerance. Helm charts will be updated for automated deployment of containerized applications. Additionally, NodePools will be reconfigured to include GPU-enabled nodes for AI processing workloads. The new setup will leverage GKE Autopilot mode to ensure optimal resource utilization and autoscaling.', '2024-11-11', 'Improved application performance and scalability', 'immediately', 'high risk', 'cluster scaling', 'under review', 'peer-reviewed', 'planned'),\n",
    "   ('AB1675', 'This change request proposes a complete overhaul of the internal load balancing mechanism for the web application deployed across AWS Elastic Load Balancers (ELB). The current setup uses a classic load balancer with static routing, which has shown limitations during high-traffic events. The new architecture will involve configuring an Application Load Balancer (ALB) with path-based routing and host-based routing to improve traffic management. AWS WAF (Web Application Firewall) rules will be enhanced to mitigate against OWASP Top 10 vulnerabilities. Additionally, integration with AWS Lambda will enable real-time anomaly detection, with traffic rerouting to spare instances during detected spikes.', '2024-11-11', 'Improved traffic management and security', 'within release window', 'high risk', 'traffic optimization', 'approved', 'uniform agreement', 'planned'),\n",
    "   ('AB1676', 'This change request details the upgrade of the enterprise Active Directory (AD) infrastructure from Windows Server 2016 to 2022 to support modern authentication protocols like FIDO2 and passwordless login. The update will include the migration of all domain controllers to new virtual machines hosted on VMware vSphere 7.0, with the introduction of a read-only domain controller (RODC) at remote offices for improved security. Group Policy Objects (GPOs) will be reviewed and refactored to comply with the latest security hardening guidelines. Additionally, the AD Federation Services (ADFS) will be upgraded to support integration with Azure AD for hybrid cloud management.', '2024-11-11', 'Enhanced security and modernized authentication', 'within release window', 'moderate risk', 'security enhancement', 'approved', 'peer-reviewed', 'planned'),\n",
    "   ('AB1677', 'This change request involves the deployment of a multi-region Redis cluster to improve data caching and reduce latency for geographically distributed users. The Redis cluster will be deployed across AWS regions using the ElastiCache service, with automatic failover and cross-region replication to ensure high availability. Each region will host a master Redis node, with slave nodes configured for read scaling. The Redis setup will also be integrated with AWS CloudWatch for real-time performance monitoring and alerting. The implementation will occur during the planned maintenance window, with minimal downtime expected due to pre-warming of the cache nodes.', '2024-11-11', 'Improved data caching and reduced latency', 'within release window', 'moderate risk', 'performance optimization', 'approved', 'no peer review', 'unplanned'),\n",
    "   ('AB1678', 'This change request proposes the integration of a new AI-based fraud detection module into the transactional systems of the company’s banking platform. The AI model, built with TensorFlow and trained on historical transaction data, will run as a microservice within Kubernetes. The integration will involve the configuration of RESTful API endpoints using Kong API Gateway, which will interface with the transactional database in PostgreSQL. The system will use machine learning techniques such as anomaly detection and supervised learning to flag high-risk transactions in real-time. Full integration will be done in the staging environment for two weeks before going live.', '2024-11-11', 'Enhanced fraud detection capabilities', 'immediately', 'high risk', 'service integration', 'new', 'peer-reviewed', 'planned'),\n",
    "   ('AB1679', 'This change request involves the transition from traditional on-premises VMware ESXi hosts to a fully managed Kubernetes container orchestration platform in Microsoft Azure Kubernetes Service (AKS). The shift will include replatforming legacy Java-based applications, which are currently running on VMs, to microservices within Kubernetes clusters. ACI (Azure Container Instances) will be used to handle burst workloads, while Azure Blob Storage will be used to manage static data. The deployment will utilize Azure DevOps pipelines for CI/CD automation and will implement Azure Monitor for application performance tracking. The final migration will happen after load testing and validation in the Azure staging environment.', '2024-11-11', 'Improved scalability and cloud-native deployment', 'after approval', 'high risk', 'cloud migration', 'approved', 'manager override', 'unplanned'),\n",
    "   ('AB1680', 'This change request is focused on the implementation of a centralized logging system using the ELK stack (Elasticsearch, Logstash, Kibana) to collect and analyze application logs across all microservices in the production environment. The ELK cluster will be set up in a dedicated VPC to segregate the traffic from other application components. Logstash will be configured to parse logs from various services, including web servers, application servers, and databases, with Elasticsearch providing the backend for querying logs. Kibana dashboards will be set up for real-time visualization of log data, with automated alerts for anomaly detection. The setup will be tested first in the staging environment before production deployment.', '2024-11-11', 'Centralized logging and real-time monitoring', 'within maintenance window', 'low risk', 'monitoring system installation', 'approved', 'peer-reviewed', 'planned'),\n",
    "   ('AB1681', 'This change request proposes the configuration of a distributed tracing system using OpenTelemetry and Jaeger to track and optimize the performance of microservices running on AWS Fargate. The Jaeger collector will be deployed in a highly available setup using EC2 instances across multiple availability zones. Application code will be instrumented with OpenTelemetry SDKs for distributed tracing, and traces will be stored in Amazon RDS for historical analysis. The system will also use AWS X-Ray for integration with AWS-native services. Real-time performance metrics will be visible in Grafana dashboards, and alerts will be configured for high latency or failures.', '2024-11-11', 'Improved application performance and observability', 'within release window', 'moderate risk', 'performance optimization', 'under review', 'uniform agreement', 'planned'),\n",
    "   ('AB1682', 'This change request involves the update of the firewall rules and access control lists (ACLs) in the internal network to tighten security and comply with new regulatory requirements. The firewall will be reconfigured to allow only specific IP ranges from known partners and block all unsolicited inbound traffic. Additionally, VLANs will be configured to segment traffic between different departments, and redundant firewall appliances will be deployed for failover. The changes will be tested in a lab environment before implementation, with logs being forwarded to a Splunk server for real-time analysis.', '2024-11-11', 'Enhanced network security and regulatory compliance', 'immediately', 'high risk', 'security hardening', 'new', 'no peer review', 'unplanned'),\n",
    "   ('AB1683', 'This change request focuses on upgrading the company’s legacy virtual desktop infrastructure (VDI) from Citrix XenDesktop 7.15 to Citrix Virtual Apps and Desktops 2203. The upgrade will include a complete re-architecting of the Citrix Delivery Controller, Citrix StoreFront, and Citrix Workspace, with the migration of all user profiles and settings to the new environment. Citrix ADC (formerly NetScaler) will also be upgraded to improve session management and load balancing. The new environment will be configured for high availability using Citrix Cloud and integrated with Microsoft Azure AD for single sign-on capabilities. Full user acceptance testing will be conducted in a parallel environment before the final migration.', '2024-11-11', 'Improved virtual desktop experience and scalability', 'within maintenance window', 'moderate risk', 'VDI upgrade', 'approved', 'peer-reviewed', 'planned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59beacfd-a764-489e-ab93-80fc1e621c05",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell1",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "def generate_risk_prediction_prompt(cr_data):\n",
    "    prompt = f\"\"\"\n",
    "            <role>\n",
    "            You are an experienced dev ops professional deeply knowledgeable on computer systems that support a very large company and the metadata that is captured about change requests.\n",
    "            A change request is a formal proposal for an alteration to the computer system that you manage.\n",
    "            As a dev ops expert, you specialize in using the metadata provided about a change request to predict the liklihood of the change request unintentionally destabalizing the computer system.\n",
    "            You are going to be provided with change request meta data as a json object held between <cr_data> and your job is to provide a prediction score and reasoning behind the risk score in the <output> section. \n",
    "            </role>\n",
    "        \n",
    "            <task>: Follow these instructions,\n",
    "            1) Considering the <cr_data> and your <role>, provide a risk score between 0 to 5 of this change request destabalizing the computer system when deployed. Output this as [Risk_Score]. Then,\n",
    "            2) Considering the <cr_data> and your <role>, provide a reasoning for the risk score in as few words as possible while maintaining all detail needed to understand your reasoning. Output this as [Risk_Score_Reason]\n",
    "            </task>\n",
    "\n",
    "            <cr_data>\n",
    "            {cr_data}\n",
    "            </cr_data>\n",
    "        \n",
    "            <Output> \n",
    "            produce valid JSON. Absolutely do not include any additional text before or following the JSON. Output should use following <JSON_format>\n",
    "            </Output>\n",
    "            \n",
    "            <JSON_format>\n",
    "            {{\n",
    "                \"Risk_Score\": (A risk score between 0 to 5 of this change request destabalizing the computer system when deployed),\n",
    "                \"Risk_Score_Reason\": (A concise resoning for the Risk_Score),\n",
    "            }}\n",
    "            </JSON_format>\n",
    "            \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f32168-3f6e-4818-9481-4e9151295e8c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell2",
    "resultHeight": 422
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from snowflake.cortex import Complete\n",
    "from snowflake.snowpark.functions import col, call_udf\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "#get a session\n",
    "session = get_active_session()\n",
    "\n",
    "#replace this with your table\n",
    "database = 'GEN_AI'\n",
    "schema = 'PUBLIC'\n",
    "table = 'ChangeRequests'\n",
    "\n",
    "#get the data into pandas\n",
    "#this could be any data but I am using summaries of state of the unions-- replace this with whatever you want.\n",
    "df = session.table(f\"{database}.{schema}.{table}\").to_pandas()\n",
    "\n",
    "#each row's columns are collapsed into a json object. that is easier to pass to the model\n",
    "#NOTICE: I am calling my generate_prompt function and passing my row as json.\n",
    "#NOTICE that I am calling complete function here (https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex)\n",
    "    # VALUE CALLOUT: I could switch out any LLM I have access to (https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability)\n",
    "df['RISK_ASSESSMENT'] = df.apply(lambda row: Complete('mistral-large2', generate_risk_prediction_prompt(row.to_json())), axis = 1)\n",
    "\n",
    "#!!look into call_udf amd call function for further efficiency gain via parallelisation!!\n",
    "    # call_udf: https://docs.snowflake.com/en/developer-guide/snowpark/python/calling-functions#calling-user-defined-functions-udfs\n",
    "    # call_function: https://docs.snowflake.com/en/developer-guide/snowpark/python/calling-functions#calling-system-defined-functions\n",
    "\n",
    "#show us the data\n",
    "st.dataframe(df['RISK_ASSESSMENT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
